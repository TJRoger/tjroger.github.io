---
layout: post
title: 一篇文章教你学会如何区分准确率、精准率、召回率，F1分值以及它们的含义
categories:
- 机器学习
tags:
- 机器学习，准确率，精准率，召回率,F1 Score
---



##内容  
准确率（Accuracy），精准率（Precision）和召回率（Recall）是分类问题中常用的三个评估指标。

准确率：指分类正确的样本数占总样本数的比例，包括真正例（TP）和真负例（TN）。准确率适用于类别平衡的情况，即正例和负例数量相当。

精准率：指预测为正例的样本中真正的正例比例，即真正例（TP）占所有预测为正例（TP+FP）的比例。精准率关注的是预测为正例的准确性。

召回率：指实际正例中被预测为正例的比例，即真正例（TP）占所有实际正例（TP+FN）的比例。召回率关注的是预测正例的覆盖度。

这三个指标之间存在一定的关系：提高精准率可能会降低召回率，反之亦然。因此，在实际应用中，需要根据具体需求来权衡这三个指标，以达到最佳的分类效果。

F1 Score/F-Measure是一个统计学中用来衡量二分类模型精确度的指标，同时兼顾了分类模型的准确率和召回率。

TP(True Positive, 真阳性)：算法预测为正例（P），实际上也是正例（P）的个数，即算法预测对了（True）。  
TN(True Negtive，真阴性)：算法预测为负例（N），实际上也是负例（N）的个数，即算法预测对了（True）。  
FP(False Positive，假阳性)：算法预测为正例（P），实际上是负例（N）的个数，即算法预测错了（False）这里指的是：实际为负例但被分类器划分为正例的实例数。  
FN(False Negtive，假阴性)：算法预测为负例（N），实际上是正例（P）的个数，即算法预测错了（False）这里指的是：即实际为正例但被分类器划分为负例的实例数  
**Accuracy = (TP+TN)/(TP+FP+TN+FN)**  
**Precision = TP / (TP+FP)**  
**Recall = TP / (TP + FN)**  
**F1 = 2 * (precision * recall) / (precision + recall)**  

----
